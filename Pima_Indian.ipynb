{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 400px; height: 160px;\">\n",
    "    <img src=\"rplogo_small.png\" width=\"100%\" height=\"100%\" align=\"left\">\n",
    "</div>\n",
    "\n",
    "###     TIPP - AAI Assignement (Machine Learning Fundamentals)<br>Due Date: 19 February 2020\n",
    "###     Submitted By: <u>KOAY</u> SENG TIAN<br>Email: sengtian@yahoo.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The [Pima](https://en.wikipedia.org/wiki/Pima_people) are a group of Native Americans living in Arizona. [Source](https://www.andreagrandi.it/2018/04/14/machine-learning-pima-indians-diabetes/) A genetic predisposition allowed this group to survive normally to a diet poor of carbohydrates for years. In the recent years, because of a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, made them develop the highest prevalence of type 2 diabetes and for this reason they have been the subject of many studies. \n",
    "\n",
    "This dataset was originally from the 'National Institute of Diabetes and Digestive and Kidney Diseases'.  The objective is to predict, based on diagnostic measurements whether a patient has diabetes.  Several constraints were placed on the selection of these instances from a larger database.  In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "__Data Source:__ [Kaggle](https://www.kaggle.com/kumargh/pimaindiansdiabetescsv)\n",
    "\n",
    "# Data Understanding\n",
    "The dataset includes data from 768 women with eight characteristics.   \n",
    "- **Pregnancies:** Number of times pregnant\n",
    "- **Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- **BloodPressure:** Diastolic blood pressure (mm Hg)\n",
    "- **SkinThickness:** Triceps skin fold thickness (mm)\n",
    "- **Insulin:** 2-Hour serum insulin (mu U/ml)\n",
    "- **BMI:** Body mass index (weight in kg/(height in m)^2)\n",
    "- **DiabetesPedigreeFunction:** Diabetes pedigree function\n",
    "- **Age:** Age (years)\n",
    "\n",
    "The last column being the person was diagnosed with diabetes (1) or not (0).\n",
    "- Outcome: Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPP - AAI Assignment (Machine Learning Fundamentals)\n",
    "# Date Due: 19 February 2020\n",
    "# Submited By: KOAY SENG TIAN\n",
    "# Email: sengtian@yahoo.com\n",
    "#\n",
    "# GitHub: https://github.com/koayst/rp_machinelearning_assignment\n",
    "#\n",
    "# load the modules/packages.\n",
    "# If there is an error, need to install the modules/packages\n",
    "# also list the version being used here\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "#instruction => pip install xgboost\n",
    "import xgboost\n",
    "\n",
    "import warnings\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "# for debugging purposes: in case want to know\n",
    "# the versions of the modules being imported\n",
    "#\n",
    "# show the versions of modules/packages imported\n",
    "# print('Version(s):\\n')\n",
    "# print('python =', python_version())\n",
    "\n",
    "# print('mathplotlib =', matplotlib.__version__)\n",
    "# print('numpy =', np.__version__)\n",
    "# print('pandas =', pd.__version__)\n",
    "# print('pickel = ', pickle.format_version)\n",
    "# print('seaborn =', sns.__version__)\n",
    "# print('sklearn =', sklearn.__version__)\n",
    "# print('xgboost =', xgboost.__version__)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the file is found in the same directory as this jupyter notebook\n",
    "#another file, pima-indians-diabetes.names for reference\n",
    "def load_dataset():\n",
    "    print('Load dataset.')\n",
    "\n",
    "    filedir = 'data'\n",
    "    filename='pima-indians-diabetes.csv'\n",
    "    filepath = os.path.join(os.getcwd(), filedir)\n",
    "\n",
    "    df = pd.read_csv(os.path.join(filepath, filename))\n",
    "    print('-' + os.path.join(filepath, filename))\n",
    "    \n",
    "    if mode == 'jupyter':\n",
    "        print('\\n-Rows => {}, Columns => {}\\n'.format(df.shape[0], df.shape[1]))\n",
    "        print(df.head(5))\n",
    "        print()\n",
    "        print(df.tail(5))\n",
    "        print()\n",
    "        print(df.info())\n",
    "        print()\n",
    "    \n",
    "    print()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null - looks like there is none\n",
    "def prepare_dataset(df):\n",
    "    print('Prepare dataset.')\n",
    "    if mode == 'jupyter':\n",
    "        print('-Perform checks:\\n')\n",
    "        print('-Any NULL value in the dataset (True=there is Null)?')\n",
    "        print(df.isnull().values.any())\n",
    "\n",
    "        print('=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        print('-Null values count in each feature:\\n')\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        #check for any cell that is missing in dataframe - look like no missing cell\n",
    "        print('=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        print('-Any cell is missing in table (True=there is missing cell)?')\n",
    "        print(df.isna().any().any())\n",
    "        print('=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        print('-Check zero value cell in the table.')\n",
    "        df.eq(0).sum()\n",
    "    \n",
    "    df[['Glucose', 'BloodPressure', 'SkinThickness', \n",
    "        'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']] = \\\n",
    "    df[['Glucose', 'BloodPressure', 'SkinThickness', \n",
    "        'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']].replace(0, np.NaN)\n",
    "\n",
    "    # use the median to fill out the zero value cells\n",
    "    print('-Replace all zeros with median value.')\n",
    "    df.fillna(df.median(axis=0), inplace=True)\n",
    "    \n",
    "    if mode == 'jupyter':\n",
    "        print('-Zero values are replaced by its median.')\n",
    "        print('=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "        print('-Check AGAIN for zero value cell.')\n",
    "        df.eq(0).sum()\n",
    "        \n",
    "        descT = df.describe().transpose()\n",
    "        cols = list(descT)\n",
    "\n",
    "        #move 'max' column next to 'min' column for easier visual comparison\n",
    "        cols.insert(cols.index('25%'), cols.pop(cols.index('max')))\n",
    "        descT = descT.loc[:, cols]\n",
    "        print(descT)\n",
    "        print()\n",
    "        \n",
    "        df.hist(bins=20, figsize=(10,10))\n",
    "        plt.show()\n",
    "\n",
    "        #looking at the 'pregnancies' histogram, there zero value\n",
    "        #This is reasonable as it is likely that a woman has never pregnant\n",
    "        \n",
    "        print('-Class imbalance visualisation.')\n",
    "\n",
    "        #now show it as a horizontal bar chart using percentage\n",
    "        sns.set(style=\"whitegrid\")\n",
    "\n",
    "        ax = sns.countplot(y=\"Outcome\", data=df)\n",
    "        ax.set_xlim(0, 600)\n",
    "\n",
    "        total = len(df['Outcome'])\n",
    "\n",
    "        for p in ax.patches:\n",
    "            percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n",
    "            x = p.get_x() + p.get_width()\n",
    "            y = p.get_y() + p.get_height()/2\n",
    "            ax.annotate(percentage, (x, y))\n",
    "        \n",
    "        #plot the correlation as heatmap\n",
    "        corr = df.corr(method='pearson')\n",
    "\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        mask = np.triu(corr, k=1)\n",
    "        sns.heatmap(corr, fmt=\".2f\", annot=True, vmin=-1, vmax=1, center= 0, cmap='RdBu_r', mask=mask, ax=ax)\n",
    "        \n",
    "        corr.nlargest(9, 'Outcome').Outcome\n",
    "        # notice that order of feature importances are:\n",
    "        \n",
    "    print()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def iterateAndTestModelAccuracy(classifier_testList, X_train, y_train, X_test, y_test):\n",
    "    for model in classifier_testList: \n",
    "        np.random.seed(42)\n",
    "        clf = model()\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict = clf.predict(X_test)\n",
    "        accu = roc_auc_score(y_test, predict)\n",
    "        cm = confusion_matrix(y_test, predict)\n",
    "        if mode == 'jupyter':\n",
    "            print('-=-=-={}-=-=-='.format(model.__name__))\n",
    "            print('-ROC AUC = {}%\\n'.format(round(accu*100, 2)))\n",
    "            print(pd.crosstab(y_test, predict, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "        \n",
    "def findModelBestParams(classifier, gParams, X_train, y_train):\n",
    "    model = classifier()\n",
    "    gs = GridSearchCV(estimator=model, \n",
    "                  param_grid=gParams, \n",
    "                  scoring='roc_auc',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    if mode == 'jupyter':\n",
    "        print('-=-=-={}-=-=-=-'.format(classifier.__name__))\n",
    "        print('-Best parameters => {}'.format(gs.best_params_))\n",
    "        print('-Best score => {}'.format(gs.best_score_))\n",
    "    return gs.best_params_\n",
    "\n",
    "def train_model(cname, df):\n",
    "    \n",
    "    print('Train model.')\n",
    "    \n",
    "    rowsList=[]\n",
    "    \n",
    "    X = df[cname].values\n",
    "    y = df.iloc[:, 8:].values\n",
    "    y = np.squeeze(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=df.Outcome)\n",
    "\n",
    "    if mode == 'jupyter':\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_test.shape)\n",
    "        print()\n",
    "        \n",
    "    print('-Scale the features.')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    if mode == 'jupyter':\n",
    "        print(type(X_train))\n",
    "        print(type(X_test))\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print()\n",
    "        \n",
    "    print('-Search ideal model.')\n",
    "    for model in [\n",
    "        DummyClassifier,\n",
    "        GaussianNB,\n",
    "        KNeighborsClassifier,\n",
    "        LogisticRegression,\n",
    "        RandomForestClassifier,\n",
    "        SVC,\n",
    "        XGBClassifier]:\n",
    "\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "        classifier = model()\n",
    "        result = model_selection.cross_val_score(classifier, X_train, y_train, scoring='roc_auc', cv=kfold)\n",
    "        dict = {'Classifier': model.__name__, 'ROC_AUC': result.mean(), 'STD': result.std()}\n",
    "        rowsList.append(dict)\n",
    "\n",
    "    if mode == 'jupyter':\n",
    "        dfModelRanking = pd.DataFrame(rowsList)\n",
    "        print(dfModelRanking.sort_values(by='ROC_AUC', ascending=False))\n",
    "        \n",
    "    print('-Narrow to top 3 models.\\n')\n",
    "    clf_list = [\n",
    "        XGBClassifier,\n",
    "        LogisticRegression,\n",
    "        GaussianNB\n",
    "    ]\n",
    "    \n",
    "    if model == 'jupyter':\n",
    "        iterateAndTestModelAccuracy(clf_list, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    gridParams= {\n",
    "        'max_depth': [2],\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree' : [0.6],\n",
    "        'verbosity' : [0]\n",
    "    }\n",
    "\n",
    "    print('-Find best paramters for XGClassifier (XGBoost).')\n",
    "    xgb_bestParams = findModelBestParams(XGBClassifier, gridParams, X_train, y_train)\n",
    "    xgb_classifier = XGBClassifier (**xgb_bestParams)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    xgb_predict = xgb_classifier.predict(X_test)\n",
    "\n",
    "    xgb_rocauc = roc_auc_score(y_test, xgb_classifier.predict_proba(X_test)[:,1])\n",
    "    cm = confusion_matrix(y_test, xgb_predict)\n",
    "    if mode == 'jupyter':\n",
    "        print('-=-=-=XGClassifier-=-=-=')\n",
    "        print('ROC AUC = {}%'.format(round(xgb_rocauc * 100, 2)))\n",
    "        pd.crosstab(y_test, xgb_predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "        print()\n",
    "        \n",
    "    gridParams= {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'random_state' : [42]\n",
    "    }\n",
    "\n",
    "    print('-Find best paramters for LogisticRegression.')\n",
    "    lr_bestParams = findModelBestParams(LogisticRegression, gridParams, X_train, y_train)\n",
    "    lr_classifier = LogisticRegression(**lr_bestParams)\n",
    "    lr_classifier.fit(X_train, y_train)\n",
    "    lr_predict = lr_classifier.predict(X_test)\n",
    "\n",
    "    lr_auc = roc_auc_score(y_test, lr_classifier.predict_proba(X_test)[:,1])\n",
    "    cm = confusion_matrix(y_test, lr_predict)\n",
    "    if mode == 'jupyter':\n",
    "        print('-=-=-=LogisticRegression-=-=-=')\n",
    "        print('ROC AUC = {}%'.format(round(lr_auc * 100, 2)))\n",
    "        pd.crosstab(y_test, lr_predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "        print()\n",
    "    \n",
    "    gridParams= {\n",
    "    }\n",
    "    print('-Find best paramters for GaussianNB.')\n",
    "    gnb_bestParams = findModelBestParams(GaussianNB, gridParams, X_train, y_train)\n",
    "    gnb_classifier = GaussianNB (**gnb_bestParams)\n",
    "    gnb_classifier.fit(X_train, y_train)\n",
    "    gnb_predict = gnb_classifier.predict(X_test)\n",
    "\n",
    "    gnb_auc = roc_auc_score(y_test, gnb_classifier.predict_proba(X_test)[:,1])\n",
    "    cm = confusion_matrix(y_test, gnb_predict)\n",
    "    if mode == 'jupyter':\n",
    "        print('-=-=-=GaussianNB-=-=-=')\n",
    "        print('ROC AUC = {}%'.format(round(gnb_auc * 100, 2)))\n",
    "        pd.crosstab(y_test, gnb_predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "        print()\n",
    "        \n",
    "    if model == 'jupyter':\n",
    "        print('Using XGBoost as a model to classify the dataset.')\n",
    "        print()\n",
    "        print('--- Metrices ---\\n')\n",
    "        print('XGBoost:')\n",
    "        print(classification_report(y_true=y_test, y_pred=xgb_predict))\n",
    "        print('-------------------------------------------------------')\n",
    "        print('Logistic Regression:')\n",
    "        print(classification_report(y_true=y_test, y_pred=lr_predict))\n",
    "        print('-------------------------------------------------------')\n",
    "        print('GaussianNB:')\n",
    "        print(classification_report(y_true=y_test, y_pred=gnb_predict))\n",
    "        print()\n",
    "        \n",
    "    bestAUC = { 'xgboost': 0, 'logisticregression' : 0, 'gaussianNB' : 0}\n",
    "    xgb_probs = xgb_classifier.predict_proba(X_test)\n",
    "    xgb_preds = xgb_probs[:,1]\n",
    "    xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_preds)\n",
    "    xgb_rocauc = auc(xgb_fpr, xgb_tpr)\n",
    "    bestAUC['xgboost'] = xgb_rocauc\n",
    "    if mode == 'jupyter':\n",
    "        print(xgb_rocauc)\n",
    "\n",
    "    lr_probs = lr_classifier.predict_proba(X_test)\n",
    "    lr_preds = lr_probs[:,1]\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_preds)\n",
    "    lr_rocauc = auc(lr_fpr, lr_tpr)\n",
    "    bestAUC['logisticregression'] = lr_rocauc\n",
    "    if mode == 'jupyter':\n",
    "        print(lr_rocauc)\n",
    "\n",
    "    gnb_probs = gnb_classifier.predict_proba(X_test)\n",
    "    gnb_preds = gnb_probs[:,1]\n",
    "    gnb_fpr, gnb_tpr, _ = roc_curve(y_test, gnb_preds)\n",
    "    gnb_rocauc = auc(gnb_fpr, gnb_tpr)\n",
    "    bestAUC['gaussianNB'] = gnb_rocauc\n",
    "    if mode == 'jupyter':\n",
    "        print(gnb_rocauc)\n",
    "\n",
    "    if mode == 'jupyter':\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot([0, 1], [0, 1], 'r--')\n",
    "        plt.plot(xgb_fpr, xgb_tpr, 'brown', label='XGBoost %.4f' % xgb_rocauc)\n",
    "        plt.plot(lr_fpr, lr_tpr, 'g-', label='LRegression %.4f' % lr_rocauc)\n",
    "        plt.plot(gnb_fpr, gnb_tpr, 'b-', label='GaussianNB %.4f' % gnb_rocauc)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Below show which features are important in the prediction.\")\n",
    "        xgboost.plot_importance(xgb_classifier).set_yticklabels(cname)\n",
    "        plt.title(\"xgboost.plot_importance(model)\")\n",
    "        plt.show()\n",
    "    \n",
    "    print('-model is ' + max(bestAUC, key=bestAUC.get))\n",
    "    print()\n",
    "    return xgb_classifier, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_filename, scaler_filename, classifier, scaler):\n",
    "    print('Save model.')\n",
    "    filedir = os.path.join(os.getcwd(), 'model')\n",
    "    filepath = os.path.join(filedir, model_filename)\n",
    "    pickle.dump (classifier, open(filepath, 'wb'))\n",
    "    print(filepath)\n",
    "    \n",
    "    print('\\nSave scaler.')\n",
    "    scaler_filename = 'pima-indians-scaler.pkl'\n",
    "    filedir = os.path.join(os.getcwd(), 'model')\n",
    "    filepath = os.path.join(filedir, scaler_filename)\n",
    "    pickle.dump (scaler, open(filepath, 'wb'))\n",
    "    print(filepath)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_filename, scaler_filename):\n",
    "    print('Load model.')\n",
    "    filedir=os.path.join(os.getcwd(), 'model')\n",
    "    filepath = os.path.join(filedir, model_filename)\n",
    "    loaded_model = pickle.load (open(filepath, 'rb'))\n",
    "\n",
    "    print('Load scaler.')\n",
    "    filedir = os.path.join(os.getcwd(), 'model')\n",
    "    filepath = os.path.join(filedir, scaler_filename)\n",
    "    loaded_scaler = pickle.load(open(filepath, 'rb'))\n",
    "    \n",
    "    print()\n",
    "    return loaded_model, loaded_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiabetesLikelihood(data, loaded_model, loaded_scaler):\n",
    "\n",
    "    data = loaded_scaler.transform([data])\n",
    "\n",
    "    prediction = loaded_model.predict(data)\n",
    "    if prediction[0] == 1:\n",
    "        print('Diabetes risk is High')\n",
    "    else:\n",
    "        print('Diabetes risk is Low')\n",
    "    confidence = loaded_model.predict_proba(data)\n",
    "    print(confidence)\n",
    "    print('Confidence: ' + str(round(confidence[0][prediction[0]] * 100, 2)) + \"%\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cname = ['Glucose', 'BMI', 'Age', 'Pregnancies'] \n",
    "testdata = [\n",
    "    [93, 30.4, 23, 1],\n",
    "    [148, 33.6, 50, 6]\n",
    "]\n",
    "\n",
    "#change mode to 'jupyter' if running in juputer notebook\n",
    "mode = 'script'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('=============================================================')\n",
    "print('Note: Please ensure \"xgboost\" is installed before proceeding.')\n",
    "print('Instruction:')\n",
    "print('1) pip install xgboost')\n",
    "print('2) To supress warning: python -W ignore Pima_Indian.py')\n",
    "print('=============================================================\\n')\n",
    "\n",
    "while True:\n",
    "    print('Menu\\n')\n",
    "    print('1) Load dataset.')\n",
    "    print('2) Prepare dataset. ')\n",
    "    print('3) Train model.')\n",
    "    print('4) Save model.')\n",
    "    print('5) Load model.')\n",
    "    print('6) Test Model')\n",
    "    print('0) Quit')\n",
    "    print('\\n\\nEnter your selection (1-6, or 0 to quit) ?')\n",
    "          \n",
    "    choice = int(input())\n",
    "    \n",
    "    if choice == 0:\n",
    "          break\n",
    "    elif choice == 1:\n",
    "          df = load_dataset()\n",
    "    elif choice == 2:\n",
    "          prepare_dataset(df)\n",
    "    elif choice == 3:\n",
    "          classifier, scaler = train_model (cname, df)\n",
    "    elif choice == 4:\n",
    "          save_model('pima-indians-xgboost.pkl', 'pima-indians-scaler.pkl', classifier, scaler)\n",
    "    elif choice == 5:\n",
    "          loaded_model, loaded_scaler = load_model('pima-indians-xgboost.pkl', 'pima-indians-scaler.pkl')\n",
    "    elif choice == 6:\n",
    "          for feature, value in zip(cname, testdata[0]):\n",
    "              print (feature, '=', value, end=', ')\n",
    "          print()\n",
    "          DiabetesLikelihood(testdata[0], loaded_model, loaded_scaler)\n",
    "\n",
    "          for feature, value in zip(cname, testdata[1]):\n",
    "              print (feature, '=', value, end=', ')\n",
    "          print()\n",
    "          DiabetesLikelihood(testdata[1], loaded_model, loaded_scaler)\n",
    "    else:\n",
    "          continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
